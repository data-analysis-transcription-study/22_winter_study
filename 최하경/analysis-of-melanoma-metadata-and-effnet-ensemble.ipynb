{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Analysis of SIIM-ISIC Melanoma Classification Metadata and Images\n\n\n**확인하고자 하는 것**\n- 데이터가 어떻게 생겼는지\n- 데이터셋이 완벽한지\n- target 분포가 어떤지 (unbalance 확인)\n- 스캔된 위치가 결과에 어떤 영향을 주는지\n- 나이가 피부 병변(skin lesion)에 영향을 주는지\n- 성별에 따라 차이가 있는지\n- 유니크한 환자 데이터가 얼마나 있는지 & 중요한지\n- 이미지 퀄리티나 색깔, 사이즈가 결과에 영향을 미치는지\n- train, test data들에서 비슷한 관찰결과들이 보이는지 & 아니라면 그 원인","metadata":{}},{"cell_type":"markdown","source":"# Loading packages","metadata":{}},{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-21T10:05:04.682852Z","iopub.execute_input":"2022-02-21T10:05:04.683463Z","iopub.status.idle":"2022-02-21T10:05:14.587071Z","shell.execute_reply.started":"2022-02-21T10:05:04.683309Z","shell.execute_reply":"2022-02-21T10:05:14.586366Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# loading packages\n\nimport pandas as pd\nimport numpy as np\n\n#\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\n#\n\nimport seaborn as sns\nimport plotly.express as px\n\n#\n\nimport os\nimport random\nimport re\nimport math\nimport time\n\nfrom tqdm import tqdm\nfrom tqdm.keras import TqdmCallback\n\n\nfrom pandas_summary import DataFrameSummary\n\nimport warnings\n\n\nwarnings.filterwarnings('ignore') # Disabling warnings for clearer outputs\n\n\n\nseed_val = 42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-02-21T10:05:14.589606Z","iopub.execute_input":"2022-02-21T10:05:14.589849Z","iopub.status.idle":"2022-02-21T10:05:22.031627Z","shell.execute_reply.started":"2022-02-21T10:05:14.589819Z","shell.execute_reply":"2022-02-21T10:05:22.030675Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Setting color palette.\norange_black = [\n    '#fdc029', '#df861d', '#FF6347', '#aa3d01', '#a30e15', '#800000', '#171820'\n]\n\n# Setting plot styling.\nplt.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:22.033228Z","iopub.execute_input":"2022-02-21T10:05:22.033530Z","iopub.status.idle":"2022-02-21T10:05:22.038815Z","shell.execute_reply.started":"2022-02-21T10:05:22.033493Z","shell.execute_reply":"2022-02-21T10:05:22.037855Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Setting file paths for our notebook:\n\nbase_path = '/kaggle/input/siim-isic-melanoma-classification'\ntrain_img_path = '/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\ntest_img_path = '/kaggle/input/siim-isic-melanoma-classification/jpeg/test/'\nimg_stats_path = '/kaggle/input/melanoma2020imgtabular'","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:22.040218Z","iopub.execute_input":"2022-02-21T10:05:22.040507Z","iopub.status.idle":"2022-02-21T10:05:22.051240Z","shell.execute_reply.started":"2022-02-21T10:05:22.040463Z","shell.execute_reply":"2022-02-21T10:05:22.050177Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Data\n\n#### Train Dataset Consists Of: 8 features & 33126 observation\n\n1. image name -> the filename of specific image for the train set\n2. patient_id -> identifies the unique patient\n3. sex -> gender of the patient\n4. age_approx -> approx age of the patient at time of scanning\n5. anatom_site_general_challenge -> location of the scan site\n6. diagnosis -> information about the diagnosis\n7. benign_malignant - indicates scan result if it's malignant or benign\n8. target -> same as above but better for modelling since it's binary\n\n#### Test Dataset Consists Of: 5 features & 10982 observation\n\n1. image name -> the filename of specific image for the train set\n2. patient_id -> identifies the unique patient\n3. sex -> gender of the patient\n4. age_approx -> approx age of the patient at time of scanning\n5. anatom_site_general_challenge -> location of the scan site","metadata":{}},{"cell_type":"code","source":"# Loading train and test data.\n\ntrain = pd.read_csv(os.path.join(base_path, 'train.csv'))\ntest = pd.read_csv(os.path.join(base_path, 'test.csv'))\nsample = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:22.053666Z","iopub.execute_input":"2022-02-21T10:05:22.054083Z","iopub.status.idle":"2022-02-21T10:05:22.217498Z","shell.execute_reply.started":"2022-02-21T10:05:22.054041Z","shell.execute_reply":"2022-02-21T10:05:22.216639Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Checking train and test columns/rows.\n\nprint(\n    f'Train data has {train.shape[1]} features, {train.shape[0]} observations and Test data {test.shape[1]} features, {test.shape[0]} observations.\\nTrain features are:\\n{train.columns.tolist()}\\nTest features are:\\n{test.columns.tolist()}'\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:22.218900Z","iopub.execute_input":"2022-02-21T10:05:22.219144Z","iopub.status.idle":"2022-02-21T10:05:22.227994Z","shell.execute_reply.started":"2022-02-21T10:05:22.219117Z","shell.execute_reply":"2022-02-21T10:05:22.227348Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Renaming train/test columns:\n\ntrain.columns = [\n    'img_name', 'id', 'sex', 'age', 'location', 'diagnosis',\n    'benign_malignant', 'target'\n]\ntest.columns = ['img_name', 'id', 'sex', 'age', 'location']","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:22.229117Z","iopub.execute_input":"2022-02-21T10:05:22.229808Z","iopub.status.idle":"2022-02-21T10:05:22.236812Z","shell.execute_reply.started":"2022-02-21T10:05:22.229774Z","shell.execute_reply":"2022-02-21T10:05:22.236123Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Taking 5 random samples from the train data:\n\ntrain.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:22.237904Z","iopub.execute_input":"2022-02-21T10:05:22.238187Z","iopub.status.idle":"2022-02-21T10:05:22.274068Z","shell.execute_reply.started":"2022-02-21T10:05:22.238158Z","shell.execute_reply":"2022-02-21T10:05:22.273247Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Taking 5 random samples from the test data:\n\ntest.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:22.275450Z","iopub.execute_input":"2022-02-21T10:05:22.275908Z","iopub.status.idle":"2022-02-21T10:05:22.288360Z","shell.execute_reply.started":"2022-02-21T10:05:22.275876Z","shell.execute_reply":"2022-02-21T10:05:22.287465Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Missing Values\n\n1. age, sex 의 경우 가장 빈번한 값으로 대체\n2. body parts (location 피처) 의 경우 'unknown'으로 대체","metadata":{}},{"cell_type":"code","source":"# Checking missing values:\n\ndef missing_percentage(df):\n\n    total = df.isnull().sum().sort_values(\n        ascending=False)[df.isnull().sum().sort_values(ascending=False) != 0]\n    percent = (df.isnull().sum().sort_values(ascending=False) / len(df) *\n               100)[(df.isnull().sum().sort_values(ascending=False) / len(df) *\n                     100) != 0]\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n\n\nmissing_train = missing_percentage(train)\nmissing_test = missing_percentage(test)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6))\n\nsns.barplot(x=missing_train.index,\n            y='Percent',\n            data=missing_train,\n            palette=orange_black,\n            ax=ax[0])\n\nsns.barplot(x=missing_test.index,\n            y='Percent',\n            data=missing_test,\n            palette=orange_black,\n            ax=ax[1])\n\nax[0].set_title('Train Data Missing Values')\nax[1].set_title('Test Data Missing Values')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:05:22.289680Z","iopub.execute_input":"2022-02-21T10:05:22.289912Z","iopub.status.idle":"2022-02-21T10:05:22.805510Z","shell.execute_reply.started":"2022-02-21T10:05:22.289884Z","shell.execute_reply":"2022-02-21T10:05:22.804689Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## (1) Checking Variables Before Imputing\n\n피처들 분포 확인","metadata":{}},{"cell_type":"code","source":"# Creating a customized chart and giving in figsize etc.\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 9))\n\n# Creating a grid:\n\ngrid = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n\nax1 = fig.add_subplot(grid[0, :2])\n\n# Set the title.\n\nax1.set_title('Gender Distribution')\n\nsns.countplot(train.sex.sort_values(ignore_index=True),\n              alpha=0.9,\n              ax=ax1,\n              color='#fdc029',\n              label='Train')\nsns.countplot(test.sex.sort_values(ignore_index=True),\n              alpha=0.7,\n              ax=ax1,\n              color='#171820',\n              label='Test')\nax1.legend()\n\n# Customizing the second grid.\n\nax2 = fig.add_subplot(grid[0, 2:])\n\n# Plot the countplot.\n\nsns.countplot(train.location,\n              alpha=0.9,\n              ax=ax2,\n              color='#fdc029',\n              label='Train',\n              order=train['location'].value_counts().index)\nsns.countplot(test.location,\n              alpha=0.7,\n              ax=ax2,\n              color='#171820',\n              label='Test',\n              order=test['location'].value_counts().index), ax2.set_title(\n                  'Anatom Site Distribution')\n\nax2.legend()\n\n# Customizing the third grid.\n\nax3 = fig.add_subplot(grid[1, :])\n\n# Set the title.\n\nax3.set_title('Age Distribution')\n\n# Plot the histogram.\n\nsns.distplot(train.age, ax=ax3, label='Train', color='#fdc029')\nsns.distplot(test.age, ax=ax3, label='Test', color='#171820')\n\nax3.legend()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:05:22.806914Z","iopub.execute_input":"2022-02-21T10:05:22.807229Z","iopub.status.idle":"2022-02-21T10:05:24.400647Z","shell.execute_reply.started":"2022-02-21T10:05:22.807191Z","shell.execute_reply":"2022-02-21T10:05:24.399515Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## (2) Imputing Missing Data","metadata":{}},{"cell_type":"code","source":"# Filling missing anatom site values with 'unknown' tag:\n\nfor df in [train, test]:\n    df['location'].fillna('unknown', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:24.402731Z","iopub.execute_input":"2022-02-21T10:05:24.403149Z","iopub.status.idle":"2022-02-21T10:05:24.413839Z","shell.execute_reply.started":"2022-02-21T10:05:24.403085Z","shell.execute_reply":"2022-02-21T10:05:24.412828Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Double checking:\n\nids_train = train.location.values\nids_test = test.location.values\nids_train_set = set(ids_train)\nids_test_set = set(ids_test)\n\nlocation_not_overlap = list(ids_train_set.symmetric_difference(ids_test_set)) ## symmetric_difference에 대해 설명 추가\nn_overlap = len(location_not_overlap)\nif n_overlap == 0:\n    print(\n        f'There are no different body parts occuring between train and test set...'\n    )\nelse:\n    print('There are some not overlapping values between train and test set!')","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:24.415235Z","iopub.execute_input":"2022-02-21T10:05:24.415523Z","iopub.status.idle":"2022-02-21T10:05:24.428631Z","shell.execute_reply.started":"2022-02-21T10:05:24.415494Z","shell.execute_reply":"2022-02-21T10:05:24.427750Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Filling age and sex with appropriate values.\n\ntrain['sex'].fillna(train['sex'].mode()[0], inplace=True)\n\ntrain['age'].fillna(train['age'].median(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:24.433340Z","iopub.execute_input":"2022-02-21T10:05:24.433776Z","iopub.status.idle":"2022-02-21T10:05:24.451923Z","shell.execute_reply.started":"2022-02-21T10:05:24.433730Z","shell.execute_reply":"2022-02-21T10:05:24.451210Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Checking missing value counts:\n\nprint(\n    f'Train missing value count: {train.isnull().sum().sum()}\\nTest missing value count: {train.isnull().sum().sum()}'\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:24.453382Z","iopub.execute_input":"2022-02-21T10:05:24.453910Z","iopub.status.idle":"2022-02-21T10:05:24.512228Z","shell.execute_reply.started":"2022-02-21T10:05:24.453866Z","shell.execute_reply":"2022-02-21T10:05:24.511469Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Exploring the Data","metadata":{}},{"cell_type":"markdown","source":"## Scans by Anatom Site\n\ntrain, test data에서 location이 비슷한 비율이 같다.","metadata":{}},{"cell_type":"code","source":"# Train data:\n\ncntstr = train.location.value_counts().rename_axis('location').reset_index(\n    name='count')\n\nfig = px.treemap(cntstr,\n                 path=['location'],\n                 values='count',\n                 color='count',\n                 color_continuous_scale=orange_black,\n                 title='Scans by Anatom Site General Challenge - Train Data')\n\nfig.update_traces(textinfo='label+percent entry')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:24.513724Z","iopub.execute_input":"2022-02-21T10:05:24.514317Z","iopub.status.idle":"2022-02-21T10:05:25.540261Z","shell.execute_reply.started":"2022-02-21T10:05:24.514254Z","shell.execute_reply":"2022-02-21T10:05:25.539412Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Test data:\n\ncntste = test.location.value_counts().rename_axis('location').reset_index(\n    name='count')\n\nfig = px.treemap(cntste,\n                 path=['location'],\n                 values='count',\n                 color='count',\n                 color_continuous_scale=orange_black,\n                 title='Scans by Anatom Site General Challenge - Test Data')\n\nfig.update_traces(textinfo='label+percent entry')\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:05:25.541564Z","iopub.execute_input":"2022-02-21T10:05:25.541807Z","iopub.status.idle":"2022-02-21T10:05:25.631872Z","shell.execute_reply.started":"2022-02-21T10:05:25.541779Z","shell.execute_reply":"2022-02-21T10:05:25.631047Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Body Part Ratio by Gender and Target\n\n1. 순서 : head/neck > oral/genital > upper extremity\n2. 성별 간 : 비슷한 순서지만 분포가 조금 다르긴 하다.","metadata":{}},{"cell_type":"code","source":"# Creating a customized chart and giving in figsize etc.\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 9))\n# Creating a grid\ngrid = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n\n# Customizing the first grid.\n\nax1 = fig.add_subplot(grid[1, :2])\n# Set the title.\nax1.set_title('Scanned Body Parts - Female')\n\n# Plot:\n\nsns.countplot(\n    train[train['sex'] == 'female'].location.sort_values(ignore_index=True),\n    alpha=0.9,\n    ax=ax1,\n    color='#fdc029',\n    label='Female',\n    order=train['location'].value_counts().index)\nax1.legend()\n\n# Customizing the second grid.\n\nax2 = fig.add_subplot(grid[1, 2:])\n\n# Set the title.\n\nax2.set_title('Scanned Body Parts - Male')\n\n# Plot.\n\nsns.countplot(\n    train[train['sex'] == 'male'].location.sort_values(ignore_index=True),\n    alpha=0.9,\n    ax=ax2,\n    color='#171820',\n    label='Male',\n    order=train['location'].value_counts().index)\n\nax2.legend()\n\n# Customizing the third grid.\n\nax3 = fig.add_subplot(grid[0, :])\n\n# Set the title.\n\nax3.set_title('Malignant Ratio Per Body Part')\n\n# Plot.\n\nloc_freq = train.groupby('location')['target'].mean().sort_values(\n    ascending=False)\nsns.barplot(x=loc_freq.index, y=loc_freq, palette=orange_black, ax=ax3)\n\nax3.legend()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:05:25.633174Z","iopub.execute_input":"2022-02-21T10:05:25.633854Z","iopub.status.idle":"2022-02-21T10:05:26.468884Z","shell.execute_reply.started":"2022-02-21T10:05:25.633819Z","shell.execute_reply":"2022-02-21T10:05:26.467902Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# A General Look With Sunburst Chart\n\n**Sunburst chart에서 얻을 수 있는 기본적인 정보**\n- 2%만이 malignant\n- malignant image에서 남성이 차지하는 비율이 62%\n- benign image에서 성별 간 비율은 balance\n- malignant image의 location은 성별에 따라 다르다\n    - torso는 남성의 경우 가장 많았는데, 여성의 경우 39%\n    - lower extremity는 여성의 경우 26%, 남성의 경우 18%\n    - upper extremity는 여성 > 남성\n- benign image location은 malignant image보다 성별간 similarity가 더 높다","metadata":{}},{"cell_type":"code","source":"# Plotting interactive sunburst:\n\nfig = px.sunburst(data_frame=train,\n                  path=['benign_malignant', 'sex', 'location'],\n                  color='sex',\n                  color_discrete_sequence=orange_black,\n                  maxdepth=-1,\n                  title='Sunburst Chart Benign/Malignant > Sex > Location')\n\nfig.update_traces(textinfo='label+percent parent')\nfig.update_layout(margin=dict(t=0, l=0, r=0, b=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:26.470374Z","iopub.execute_input":"2022-02-21T10:05:26.470687Z","iopub.status.idle":"2022-02-21T10:05:27.249397Z","shell.execute_reply.started":"2022-02-21T10:05:26.470645Z","shell.execute_reply":"2022-02-21T10:05:27.248576Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Age and Scan Result Relations\n\n- malignant image는 young보다 elderly에서 많이 나온다\n- 모든 성별에서 85세 이상부터 spike 있다\n- 여기에서 60세 이상의 사람들이 더 malignant하다고 예측 가능\n- 여성들의 경우 15-20세에서 bump가 있긴 하다","metadata":{}},{"cell_type":"code","source":"# Plotting age vs sex vs target:\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6))\nsns.lineplot(x='age',\n             y='target',\n             data=train,\n             ax=ax[0],\n             hue='sex',\n             palette=orange_black[:2],\n             ci=None)\nsns.boxplot(x='benign_malignant',\n            y='age',\n            data=train,\n            ax=ax[1],\n            hue='sex',\n            palette=orange_black)\n\nplt.legend(loc='lower right')\n\nax[0].set_title('Malignant Scan Frequency by Age')\nax[1].set_title('Scan Results by Age and Sex')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:27.250710Z","iopub.execute_input":"2022-02-21T10:05:27.250959Z","iopub.status.idle":"2022-02-21T10:05:27.826921Z","shell.execute_reply.started":"2022-02-21T10:05:27.250931Z","shell.execute_reply":"2022-02-21T10:05:27.826317Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Age Round Two\n\n- train, test data에서 연령은 비슷하게 분포 & 75세 이상과 40세 언저리에서 bump 존재\n- 나이가 많을수록 malignant하다는 경향성을 볼 수 있다\n- 나이가 어린 사람들의 경우 여성일수록 malignant하다는 것을 추측할 수 있다","metadata":{}},{"cell_type":"code","source":"# Creating a customized chart and giving in figsize etc.\n\n# Plotting age dist vs target and age dist vs datasets\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 12))\n\n# Creating a grid\n\ngrid = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n\n# Customizing the first grid.\n\nax1 = fig.add_subplot(grid[0, :2])\n\n# Set the title.\n\nax1.set_title('Age Distribution by Scan Outcome')\n\n# Plot\n\nax1.legend()\n\nsns.kdeplot(train[train['target'] == 0]['age'],\n            shade=True,\n            ax=ax1,\n            color='#171820',\n            label='Benign')\nsns.kdeplot(train[train['target'] == 1]['age'],\n            shade=True,\n            ax=ax1,\n            color='#fdc029',\n            label='Malignant')\n\n# Customizing second grid.\n\nax2 = fig.add_subplot(grid[0, 2:])\n\n# Set the title.\n\nax2.set_title('Age Distribution by Train/Test Observations')\n\n# Plot.\n\nsns.kdeplot(train.age, label='Train', shade=True, ax=ax2, color='#171820')\nsns.kdeplot(test.age, label='Test', shade=True, ax=ax2, color='#fdc029')\n\nax2.legend()\n\n# Customizing third grid.\n\nax3 = fig.add_subplot(grid[1, :])\n\n# Set the title.\n\nax3.set_title('Age Distribution by Gender')\n\n# Plot\n\nsns.distplot(train[train.sex == 'female'].age,\n             ax=ax3,\n             label='Female',\n             color='#fdc029')\nsns.distplot(train[train.sex == 'male'].age,\n             ax=ax3,\n             label='Male',\n             color='#171820')\nax3.legend()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:05:27.828414Z","iopub.execute_input":"2022-02-21T10:05:27.829299Z","iopub.status.idle":"2022-02-21T10:05:30.042208Z","shell.execute_reply.started":"2022-02-21T10:05:27.829237Z","shell.execute_reply":"2022-02-21T10:05:30.041313Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Unique Patients and Their Scan Images","metadata":{}},{"cell_type":"code","source":"print(\n    f'Number of unique Patient ID\\'s in train set: {train.id.nunique()}, Total: {train.id.count()}\\nNumber of unique Patient ID\\'s in test set: {test.id.nunique()}, Total: {test.id.count()}'\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:30.043524Z","iopub.execute_input":"2022-02-21T10:05:30.043771Z","iopub.status.idle":"2022-02-21T10:05:30.059604Z","shell.execute_reply.started":"2022-02-21T10:05:30.043741Z","shell.execute_reply":"2022-02-21T10:05:30.058819Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train['age_min'] = train['id'].map(train.groupby(['id']).age.min())\ntrain['age_max'] = train['id'].map(train.groupby(['id']).age.max())\n\ntest['age_min'] = test['id'].map(test.groupby(['id']).age.min())\ntest['age_max'] = test['id'].map(test.groupby(['id']).age.max())","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:30.060822Z","iopub.execute_input":"2022-02-21T10:05:30.061461Z","iopub.status.idle":"2022-02-21T10:05:30.105804Z","shell.execute_reply.started":"2022-02-21T10:05:30.061418Z","shell.execute_reply":"2022-02-21T10:05:30.104773Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train['n_images'] = train.id.map(train.groupby(['id']).img_name.count())\ntest['n_images'] = test.id.map(test.groupby(['id']).img_name.count())","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:30.107214Z","iopub.execute_input":"2022-02-21T10:05:30.107573Z","iopub.status.idle":"2022-02-21T10:05:30.135223Z","shell.execute_reply.started":"2022-02-21T10:05:30.107530Z","shell.execute_reply":"2022-02-21T10:05:30.134108Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Creating a customized chart and giving in figsize etc.\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 12))\n\n# Creating a grid\n\ngrid = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n\n# Customizing the first grid.\n\nax1 = fig.add_subplot(grid[0, :2])\n\n# Set the title.\n\nax1.set_title('Number of Scans Distribution by Scan Outcome')\n\n# Plot\n\nsns.kdeplot(train[train['target'] == 0]['n_images'],\n            shade=True,\n            ax=ax1,\n            color='#171820',\n            label='Benign')\nsns.kdeplot(train[train['target'] == 1]['n_images'],\n            shade=True,\n            ax=ax1,\n            color='#fdc029',\n            label='Malignant')\n\nax1.legend()\n\n# Customizing the second grid.\n\nax2 = fig.add_subplot(grid[0, 2:])\n\n# Set the title.\n\nax2.set_title('Number of Scans Distribution by Train/Test Observations')\n\n# Plot\n\nsns.kdeplot(train.n_images, label='Train', shade=True, ax=ax2, color='#171820')\nsns.kdeplot(test.n_images, label='Test', shade=True, ax=ax2, color='#fdc029')\nax2.legend()\n\n# Customizing the third grid.\n\nax3 = fig.add_subplot(grid[1, :])\n\n# Set the title.\n\nax3.set_title('Malignant Scan Result Frequency by Number of Scans')\n\n# Plot\n\nz = train.groupby('n_images')['target'].mean()\nsns.lineplot(x=z.index, y=z, color='#171820', ax=ax3)\nax3.legend()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:05:30.136459Z","iopub.execute_input":"2022-02-21T10:05:30.136872Z","iopub.status.idle":"2022-02-21T10:05:31.556226Z","shell.execute_reply.started":"2022-02-21T10:05:30.136834Z","shell.execute_reply":"2022-02-21T10:05:31.555659Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Diagnosis Distribution","metadata":{}},{"cell_type":"code","source":"diag = train.diagnosis.value_counts()\nfig = px.pie(diag,\n             values='diagnosis',\n             names=diag.index,\n             color_discrete_sequence=orange_black,\n             hole=.4)\nfig.update_traces(textinfo='percent+label', pull=0.05)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:31.557195Z","iopub.execute_input":"2022-02-21T10:05:31.557958Z","iopub.status.idle":"2022-02-21T10:05:31.638163Z","shell.execute_reply.started":"2022-02-21T10:05:31.557909Z","shell.execute_reply":"2022-02-21T10:05:31.637198Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Loading Image Meta Features","metadata":{}},{"cell_type":"code","source":"# Getting image sizes by using os:\n\nfor data, location in zip([train, test], [train_img_path, test_img_path]):\n    images = data['img_name'].values\n    sizes = np.zeros(images.shape[0])\n    for i, path in enumerate(tqdm(images)):\n        sizes[i] = os.path.getsize(os.path.join(location, f'{path}.jpg'))\n\n    data['image_size'] = sizes","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:05:31.639595Z","iopub.execute_input":"2022-02-21T10:05:31.639993Z","iopub.status.idle":"2022-02-21T10:08:49.173839Z","shell.execute_reply.started":"2022-02-21T10:05:31.639953Z","shell.execute_reply":"2022-02-21T10:08:49.172795Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Image Sizes\n\nimage size와 target 관계 확인","metadata":{}},{"cell_type":"code","source":"# Plotting image sizes:\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6))\n\nsns.kdeplot(train[train['target'] == 0]['image_size'],\n            shade=True,\n            ax=ax[0],\n            color='#171820',\n            label='Benign')\nsns.kdeplot(train[train['target'] == 1]['image_size'],\n            shade=True,\n            ax=ax[0],\n            color='#fdc029',\n            label='Malignant')\n\nsns.kdeplot(train.image_size,\n            label='Train',\n            shade=True,\n            ax=ax[1],\n            color='#171820')\nsns.kdeplot(test.image_size,\n            label='Test',\n            shade=True,\n            ax=ax[1],\n            color='#fdc029')\n\nax[0].set_title('Scan Image Size Distribution by Scan Outcome')\nax[1].set_title('Scan Image Size Distribution by Train/Test Observations')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:08:49.175239Z","iopub.execute_input":"2022-02-21T10:08:49.175864Z","iopub.status.idle":"2022-02-21T10:08:50.210846Z","shell.execute_reply.started":"2022-02-21T10:08:49.175816Z","shell.execute_reply":"2022-02-21T10:08:50.209875Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Getting Image Attributes\n\n시간 오래 걸려서 따로 데이터로 정리해 import","metadata":{}},{"cell_type":"code","source":"#from keras.preprocessing import image\n#\n# for data, location in zip([train, test],[train_img_path, test_img_path]):\n#    images = data['img_name'].values\n#    reds = np.zeros(images.shape[0])\n#    greens = np.zeros(images.shape[0])\n#    blues = np.zeros(images.shape[0])\n#    mean = np.zeros(images.shape[0])\n#    x = np.zeros(images.shape[0], dtype=int)\n#    y = np.zeros(images.shape[0], dtype=int)\n#    for i, path in enumerate(tqdm(images)):\n#        img = np.array(image.load_img(os.path.join(location, f'{path}.jpg')))\n#\n#        reds[i] = np.mean(img[:,:,0].ravel())\n#        greens[i] = np.mean(img[:,:,1].ravel())\n#        blues[i] = np.mean(img[:,:,2].ravel())\n#        mean[i] = np.mean(img)\n#        x[i] = img.shape[1]\n#        y[i] = img.shape[0]\n#\n#    data['reds'] = reds\n#    data['greens'] = greens\n#    data['blues'] = blues\n#    data['mean_colors'] = mean\n#    data['width'] = x\n#    data['height'] = y\n#\n#train['total_pixels']= train['width']*train['height']\n#test['total_pixels']= test['width']*test['height']\n#train['res'] = train['width'].astype(str) + 'x' + train['height'].astype(str)\n#test['res'] = test['width'].astype(str) + 'x' + test['height'].astype(str)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:08:50.212097Z","iopub.execute_input":"2022-02-21T10:08:50.212393Z","iopub.status.idle":"2022-02-21T10:08:50.217933Z","shell.execute_reply.started":"2022-02-21T10:08:50.212361Z","shell.execute_reply":"2022-02-21T10:08:50.217320Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Loading color data:\n\ntrain_attr = pd.read_csv(\n    os.path.join(img_stats_path, 'train_mean_colorres.csv'))\ntest_attr = pd.read_csv(os.path.join(img_stats_path, 'test_mean_colorres.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:08:50.218993Z","iopub.execute_input":"2022-02-21T10:08:50.220008Z","iopub.status.idle":"2022-02-21T10:08:50.372963Z","shell.execute_reply.started":"2022-02-21T10:08:50.219957Z","shell.execute_reply":"2022-02-21T10:08:50.372218Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_attr.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:08:50.374224Z","iopub.execute_input":"2022-02-21T10:08:50.374817Z","iopub.status.idle":"2022-02-21T10:08:50.387990Z","shell.execute_reply.started":"2022-02-21T10:08:50.374779Z","shell.execute_reply":"2022-02-21T10:08:50.387054Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([train, train_attr], axis=1)\ntest = pd.concat([test, test_attr], axis=1)\n\ntrain['res'] = train['width'].astype(str) + 'x' + train['height'].astype(str)\ntest['res'] = test['width'].astype(str) + 'x' + test['height'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:08:50.388991Z","iopub.execute_input":"2022-02-21T10:08:50.389209Z","iopub.status.idle":"2022-02-21T10:08:50.541231Z","shell.execute_reply.started":"2022-02-21T10:08:50.389183Z","shell.execute_reply":"2022-02-21T10:08:50.540561Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Image Colors and Their Effects on Results","metadata":{}},{"cell_type":"code","source":"# Creating a customized chart and giving in figsize etc.\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 12))\n\n# Creating a grid\n\ngrid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n\n# Customizing the first grid.\n\nax1 = fig.add_subplot(grid[0, :2])\n\n# Set the title.\n\nax1.set_title('RGB Channels of Benign Images')\n\n# Plot.\n\nsns.distplot(train[train['target'] == 0].reds,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='red',\n             kde=True,\n             ax=ax1,\n             label='Reds')\nsns.distplot(train[train['target'] == 0].greens,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='green',\n             kde=True,\n             ax=ax1,\n             label='Greens')\nsns.distplot(train[train['target'] == 0].blues,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='blue',\n             kde=True,\n             ax=ax1,\n             label='Blues')\n\nax1.legend()\n\n# Customizing the second grid.\n\nax2 = fig.add_subplot(grid[1, :2])\n\n# Set the title.\n\nax2.set_title('RGB Channels of Malignant Images')\n\n# Plot\n\nsns.distplot(train[train['target'] == 1].reds,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='red',\n             kde=True,\n             ax=ax2,\n             label='Reds')\nsns.distplot(train[train['target'] == 1].greens,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='green',\n             kde=True,\n             ax=ax2,\n             label='Greens')\nsns.distplot(train[train['target'] == 1].blues,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='blue',\n             kde=True,\n             ax=ax2,\n             label='Blues')\nax2.legend()\n\n# Customizing the third grid.\n\nax3 = fig.add_subplot(grid[:, 2])\n\n# Set the title.\n\nax3.set_title('Mean Colors by Train/Test Images')\n\n# Plot\n\nsns.kdeplot(train.mean_colors,\n            shade=True,\n            label='Train',\n            ax=ax3,\n            color='#171820',\n            vertical=True)\nsns.kdeplot(test.mean_colors,\n            shade=True,\n            label='Test',\n            ax=ax3,\n            color='#fdc029',\n            vertical=True)\nax3.legend()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:08:50.542468Z","iopub.execute_input":"2022-02-21T10:08:50.542871Z","iopub.status.idle":"2022-02-21T10:08:53.336093Z","shell.execute_reply.started":"2022-02-21T10:08:50.542839Z","shell.execute_reply":"2022-02-21T10:08:53.335458Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# How are the Image Sizes Affecting Targets in Our Data","metadata":{}},{"cell_type":"code","source":"# Creating a customized chart and giving in figsize etc.\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 12))\n\n# Creating a grid\n\ngrid = gridspec.GridSpec(ncols=4, nrows=3, figure=fig)\n\n# Customizing the first grid.\n\nax1 = fig.add_subplot(grid[0, :2])\n\n# Set the title.\n\nax1.set_title('Scan Image Resolutions of Train Set')\n\n# Plot.\n\ntres = train.res.value_counts().rename_axis('res').reset_index(name='count')\ntres = tres[tres['count'] > 10]\nsns.barplot(x='res', y='count', data=tres, palette=orange_black, ax=ax1)\nplt.xticks(rotation=20)\n\nax1.legend()\n\n# Customizing the second grid.\n\nax2 = fig.add_subplot(grid[0, 2:])\n\n# Set the title.\n\nax2.set_title('Scan Image Resolutions of Test Set')\n\n# Plot\n\nteres = test.res.value_counts().rename_axis('res').reset_index(name='count')\nteres = teres[teres['count'] > 10]\nsns.barplot(x='res', y='count', data=teres, palette=orange_black, ax=ax2)\nplt.xticks(rotation=20)\nax2.legend()\n\n# Customizing the third grid.\n\nax3 = fig.add_subplot(grid[1, :])\n\n# Set the title.\n\nax3.set_title('Scan Image Resolutions by Target')\n\n# Plot.\n\nsns.countplot(x='res',\n              hue='benign_malignant',\n              data=train,\n              order=train.res.value_counts().iloc[:12].index,\n              palette=orange_black,\n              ax=ax3)\nax3.legend()\n\n# Customizing the last grid.\n\nax4 = fig.add_subplot(grid[2, :])\n\n# Set the title.\n\nax4.set_title('Malignant Scan Result Frequency by Image Resolution')\n\n# Plot.\n\nres_freq = train.groupby('res')['target'].mean()\nres_freq = res_freq[(res_freq > 0) & (res_freq < 1)]\nsns.lineplot(x=res_freq.index, y=res_freq, palette=orange_black, ax=ax4)\nax4.legend()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:08:53.337438Z","iopub.execute_input":"2022-02-21T10:08:53.337694Z","iopub.status.idle":"2022-02-21T10:08:55.010215Z","shell.execute_reply.started":"2022-02-21T10:08:53.337664Z","shell.execute_reply":"2022-02-21T10:08:55.009398Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# The Mysterious Images\n","metadata":{}},{"cell_type":"code","source":"# Creating a customized chart and giving in figsize etc.\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 14))\n\n# Creating a grid\n\ngrid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n\n# Customizing the first grid.\n\nax1 = fig.add_subplot(grid[0, :2])\n\n# Set the title.\n\nax1.set_title('RGB Channels of Train Images With \"Mysterious\" Set')\n\n# Plot.\n\nsns.distplot(train.reds,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='red',\n             kde=True,\n             ax=ax1,\n             label='Reds')\nsns.distplot(train.greens,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='green',\n             kde=True,\n             ax=ax1,\n             label='Greens')\nsns.distplot(train.blues,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='blue',\n             kde=True,\n             ax=ax1,\n             label='Blues')\n\nax1.legend()\n\n# Customizing the second grid.\n\nax2 = fig.add_subplot(grid[1, :2])\n\n# Set the title.\n\nax2.set_title('RGB Channels of Test Images Without \"Mysterious\" Set')\n\n# Plot\n\nsns.distplot(test[test['res'] != '1920x1080'].reds,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='red',\n             kde=True,\n             ax=ax2,\n             label='Reds')\nsns.distplot(test[test['res'] != '1920x1080'].greens,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='green',\n             kde=True,\n             ax=ax2,\n             label='Greens')\nsns.distplot(test[test['res'] != '1920x1080'].blues,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='blue',\n             kde=True,\n             ax=ax2,\n             label='Blues')\nax2.legend()\n\n# Customizing the third grid.\n\nax3 = fig.add_subplot(grid[:, 2])\n\n# Set the title.\n\nax3.set_title('Mean Colors by Train/Test Images Without \"Mysterious\" Set')\n\n# Plot\n\nsns.kdeplot(train.mean_colors,\n            shade=True,\n            label='Train',\n            ax=ax3,\n            color='#171820',\n            vertical=True)\nsns.kdeplot(test[test['res'] != '1920x1080'].mean_colors,\n            shade=True,\n            label='Test',\n            ax=ax3,\n            color='#fdc029',\n            vertical=True)\nax3.legend()\n\n# Customizing the last grid.\n\nax2 = fig.add_subplot(grid[2, :2])\n\n# Set the title.\n\nax2.set_title('RGB Channels of \"Mysterious\" Set')\n\n# Plot\n\nsns.distplot(test[test['res'] == '1920x1080'].reds,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='red',\n             kde=True,\n             ax=ax2,\n             label='Reds')\nsns.distplot(test[test['res'] == '1920x1080'].greens,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='green',\n             kde=True,\n             ax=ax2,\n             label='Greens')\nsns.distplot(test[test['res'] == '1920x1080'].blues,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.3\n             },\n             color='blue',\n             kde=True,\n             ax=ax2,\n             label='Blues')\nax2.legend()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:08:55.011892Z","iopub.execute_input":"2022-02-21T10:08:55.012476Z","iopub.status.idle":"2022-02-21T10:08:58.745710Z","shell.execute_reply.started":"2022-02-21T10:08:55.012427Z","shell.execute_reply":"2022-02-21T10:08:58.744769Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Creating a customized chart and giving in figsize etc.\n\n# Plotting age dist vs target and age dist vs datasets\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 12))\n\n# Creating a grid\n\ngrid = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n\n# Customizing the first grid.\n\nax1 = fig.add_subplot(grid[0, :2])\n\n# Set the title.\n\nax1.set_title('Scan Image Size Distribution by Train/Test Observations')\n\n# Plot\n\nax1.legend()\n\nsns.kdeplot(train['image_size'],\n            shade=True,\n            ax=ax1,\n            color='#171820',\n            label='Train')\nsns.kdeplot(test['image_size'],\n            shade=True,\n            ax=ax1,\n            color='#fdc029',\n            label='Test')\n\n# Customizing second grid.\n\nax2 = fig.add_subplot(grid[0, 2:])\n\n# Set the title.\n\nax2.set_title('Scan Image Size Distribution Without \"Mysterious Set\"')\n\n# Plot.\n\nsns.kdeplot(train.image_size,\n            label='Train',\n            shade=True,\n            ax=ax2,\n            color='#171820')\nsns.kdeplot(test[test['res'] != '1920x1080'].image_size,\n            label='Test',\n            shade=True,\n            ax=ax2,\n            color='#fdc029')\nax2.legend()\n\n# Customizing third grid.\n\nax3 = fig.add_subplot(grid[1, :])\n\n# Set the title.\n\nax3.set_title('Image Size Distribution of Mysterious Images')\n\n# Plot\n\nsns.distplot(test[test['res'] == '1920x1080'].image_size,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.9\n             },\n             color='#FF6347',\n             kde=True,\n             ax=ax3,\n             label='Mysterious Images')\nax3.legend()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:08:58.746925Z","iopub.execute_input":"2022-02-21T10:08:58.747215Z","iopub.status.idle":"2022-02-21T10:09:00.670407Z","shell.execute_reply.started":"2022-02-21T10:08:58.747181Z","shell.execute_reply":"2022-02-21T10:09:00.669477Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Creating a customized chart and giving in figsize etc.\n\n# Plotting age dist vs target and age dist vs datasets\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 12))\n\n# Creating a grid\n\ngrid = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n\n# Customizing the first grid.\n\nax1 = fig.add_subplot(grid[0, :2])\n\n# Set the title.\n\nax1.set_title('Number of Images Distribution by Train/Test Observations')\n\n# Plot\n\nax1.legend()\n\nsns.kdeplot(train['n_images'],\n            shade=True,\n            ax=ax1,\n            color='#171820',\n            label='Train')\nsns.kdeplot(test['n_images'],\n            shade=True,\n            ax=ax1,\n            color='#fdc029',\n            label='Test')\n\n# Customizing second grid.\n\nax2 = fig.add_subplot(grid[0, 2:])\n\n# Set the title.\n\nax2.set_title('Scan Image Size Distribution Without \"Mysterious Set\"')\n\n# Plot.\n\nsns.kdeplot(train.n_images,\n            label='Train',\n            shade=True,\n            ax=ax2,\n            color='#171820')\nsns.kdeplot(test[test['res'] != '1920x1080'].n_images,\n            label='Test',\n            shade=True,\n            ax=ax2,\n            color='#fdc029')\nax2.legend()\n\n# Customizing third grid.\n\nax3 = fig.add_subplot(grid[1, :])\n\n# Set the title.\n\nax3.set_title('Number of Images Distribution of Mysterious Images')\n\n# Plot\n\nsns.distplot(test[test['res'] == '1920x1080'].n_images,\n             hist_kws={\n                 'rwidth': 0.75,\n                 'edgecolor': 'black',\n                 'alpha': 0.9\n             },\n             color='#FF6347',\n             kde=True,\n             ax=ax3,\n             label='Mysterious Images')\nax3.legend()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:09:00.671685Z","iopub.execute_input":"2022-02-21T10:09:00.671913Z","iopub.status.idle":"2022-02-21T10:09:02.240582Z","shell.execute_reply.started":"2022-02-21T10:09:00.671880Z","shell.execute_reply":"2022-02-21T10:09:02.239414Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 6))\n\nsns.kdeplot(test[test['res'] != '1920x1080'].age,\n            shade=True,\n            label='Without Mystery Set',\n            color='#171820',\n            )\nsns.kdeplot(test[test['res'] == '1920x1080'].age,\n            shade=True,\n            label='With Mystery Set',\n            color='#fdc029',\n            )\n\nplt.legend(loc='upper right')\n\nax.set_title('Age Distribution With/Without Mysterious Set')\n\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:09:02.242027Z","iopub.execute_input":"2022-02-21T10:09:02.242386Z","iopub.status.idle":"2022-02-21T10:09:02.600544Z","shell.execute_reply.started":"2022-02-21T10:09:02.242341Z","shell.execute_reply":"2022-02-21T10:09:02.599508Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"1920x1080 image의 경우 어린 연령대가 많았다","metadata":{}},{"cell_type":"markdown","source":"# Visual Inspection of Mysterious Image Set\n","metadata":{}},{"cell_type":"code","source":"mystery = test[test['res'] == '1920x1080']\nmystimages = mystery['img_name'].values\n\nnonmystery = test[test['res'] != '1920x1080']\nnonmystimages = nonmystery['img_name'].values\n\nrandom_myst_images = [np.random.choice(mystimages+'.jpg') for i in range(12)]\nrandom_nmyst_images = [np.random.choice(nonmystimages+'.jpg') for i in range(12)]\n\n# Location of test images\nimg_dir = '../input/siim-isic-melanoma-classification/jpeg/test'","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:02.602040Z","iopub.execute_input":"2022-02-21T10:09:02.602406Z","iopub.status.idle":"2022-02-21T10:09:02.629951Z","shell.execute_reply.started":"2022-02-21T10:09:02.602361Z","shell.execute_reply":"2022-02-21T10:09:02.629232Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nfor i in range(12):\n    \n    plt.subplot(3, 4, i + 1)\n    img = plt.imread(os.path.join(img_dir, random_myst_images[i]))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \nplt.suptitle('Sample Images From Mysterious Test Set', fontsize=14)\nplt.tight_layout()   \n  ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:09:02.631060Z","iopub.execute_input":"2022-02-21T10:09:02.631411Z","iopub.status.idle":"2022-02-21T10:09:07.426654Z","shell.execute_reply.started":"2022-02-21T10:09:02.631381Z","shell.execute_reply":"2022-02-21T10:09:07.425977Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nfor i in range(12):\n    \n    plt.subplot(3, 4, i + 1)\n    img = plt.imread(os.path.join(img_dir, random_nmyst_images[i]))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off') \n    \nplt.suptitle('Sample Images From Rest of the Test Set', fontsize=14, y=1.05)\nplt.tight_layout()   ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:09:07.432462Z","iopub.execute_input":"2022-02-21T10:09:07.432852Z","iopub.status.idle":"2022-02-21T10:09:34.386084Z","shell.execute_reply.started":"2022-02-21T10:09:07.432821Z","shell.execute_reply":"2022-02-21T10:09:34.385444Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Correlations Between Features","metadata":{}},{"cell_type":"code","source":"# Display numerical correlations between features on heatmap.\n\nsns.set(font_scale=1.1)\ncorrelation_train = train[['target','age','age_min',\n 'age_max',\n 'n_images',\n 'image_size',\n 'reds',\n 'greens',\n 'blues', \n 'width',\n 'height',\n ]].corr()\nmask = np.triu(correlation_train.corr())\nplt.figure(figsize=(16, 6))\nsns.heatmap(correlation_train,\n            annot=True,\n            fmt='.1f',\n            cmap='coolwarm',            \n            mask=mask,\n            linewidths=1,\n            cbar=False)\n\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:34.387264Z","iopub.execute_input":"2022-02-21T10:09:34.387654Z","iopub.status.idle":"2022-02-21T10:09:34.963781Z","shell.execute_reply.started":"2022-02-21T10:09:34.387611Z","shell.execute_reply":"2022-02-21T10:09:34.962603Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# Modelling Based on Tabular Meta Features","metadata":{}},{"cell_type":"markdown","source":"## Getting Landscape Attributes from Images\n\nlandscape data [here.](https://www.kaggle.com/kittlein/landscape)","metadata":{}},{"cell_type":"code","source":"# Loading lanscape data\n\ntrain40 = pd.read_csv('../input/melanoma2020imgtabular/train40Features.csv')\ntest40 = pd.read_csv('../input/melanoma2020imgtabular/test40Features.csv')\n\ntrainmet = pd.read_csv('../input/melanoma2020imgtabular/trainMetrics.csv')\ntestmet = pd.read_csv('../input/melanoma2020imgtabular/testMetrics.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:34.965162Z","iopub.execute_input":"2022-02-21T10:09:34.965435Z","iopub.status.idle":"2022-02-21T10:09:38.495321Z","shell.execute_reply.started":"2022-02-21T10:09:34.965406Z","shell.execute_reply":"2022-02-21T10:09:38.494553Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Dropping duplicate data from lanscape dataset\n\ntrain40.drop(['sex', 'age_approx', 'anatom_site_general_challenge'],\n             axis=1,\n             inplace=True)\n\ntest40.drop(['sex', 'age_approx', 'anatom_site_general_challenge'],\n            axis=1,\n            inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:38.498112Z","iopub.execute_input":"2022-02-21T10:09:38.498819Z","iopub.status.idle":"2022-02-21T10:09:38.509729Z","shell.execute_reply.started":"2022-02-21T10:09:38.498777Z","shell.execute_reply":"2022-02-21T10:09:38.508908Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# merging both datasets\n\ntrain = pd.concat([train, train40, trainmet], axis=1)\ntest = pd.concat([test, test40, testmet], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:38.510980Z","iopub.execute_input":"2022-02-21T10:09:38.511257Z","iopub.status.idle":"2022-02-21T10:09:38.574275Z","shell.execute_reply.started":"2022-02-21T10:09:38.511227Z","shell.execute_reply":"2022-02-21T10:09:38.573353Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# checking out new dataset\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:38.576303Z","iopub.execute_input":"2022-02-21T10:09:38.576640Z","iopub.status.idle":"2022-02-21T10:09:38.612585Z","shell.execute_reply.started":"2022-02-21T10:09:38.576597Z","shell.execute_reply":"2022-02-21T10:09:38.611399Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# Getting Data Ready For ML Algorithms","metadata":{}},{"cell_type":"code","source":"# getting dummy variables for gender on train set\n\nsex_dummies = pd.get_dummies(train['sex'], prefix='sex')\ntrain = pd.concat([train, sex_dummies], axis=1)\n\n# getting dummy variables for gender on test set\n\nsex_dummies = pd.get_dummies(test['sex'], prefix='sex')\ntest = pd.concat([test, sex_dummies], axis=1)\n\n# dropping not useful columns\n\ntrain.drop(['sex','res','img_name','id','diagnosis','benign_malignant'], axis=1, inplace=True)\ntest.drop(['sex','res','img_name','id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:38.614083Z","iopub.execute_input":"2022-02-21T10:09:38.614827Z","iopub.status.idle":"2022-02-21T10:09:38.815534Z","shell.execute_reply.started":"2022-02-21T10:09:38.614778Z","shell.execute_reply":"2022-02-21T10:09:38.814581Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# getting dummy variables for location on train set\n\nanatom_dummies = pd.get_dummies(train['location'], prefix='anatom')\ntrain = pd.concat([train, anatom_dummies], axis=1)\n\n# getting dummy variables for location on test set\n\nanatom_dummies = pd.get_dummies(test['location'], prefix='anatom')\ntest = pd.concat([test, anatom_dummies], axis=1)\n\n# dropping not useful columns\n\ntrain.drop('location', axis=1, inplace=True)\ntest.drop('location', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:38.816859Z","iopub.execute_input":"2022-02-21T10:09:38.817489Z","iopub.status.idle":"2022-02-21T10:09:38.966222Z","shell.execute_reply.started":"2022-02-21T10:09:38.817441Z","shell.execute_reply":"2022-02-21T10:09:38.965304Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Loading Modelling Tools","metadata":{}},{"cell_type":"code","source":"# loading modelling libraries\n\nimport xgboost as xgb\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, cross_validate\nfrom sklearn.metrics import roc_auc_score, roc_curve","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:38.967517Z","iopub.execute_input":"2022-02-21T10:09:38.967756Z","iopub.status.idle":"2022-02-21T10:09:39.236657Z","shell.execute_reply.started":"2022-02-21T10:09:38.967726Z","shell.execute_reply":"2022-02-21T10:09:39.235609Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# dividing train set and labels for modelling\n\nX = train.drop('target', axis=1)\ny = train.target","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:39.238198Z","iopub.execute_input":"2022-02-21T10:09:39.238889Z","iopub.status.idle":"2022-02-21T10:09:39.267809Z","shell.execute_reply.started":"2022-02-21T10:09:39.238838Z","shell.execute_reply":"2022-02-21T10:09:39.267075Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Setting Cross-Validation and Hold-out Set","metadata":{}},{"cell_type":"code","source":"# taking holdout set for validating with stratified y\n\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.2,\n                                                    stratify=y,\n                                                    random_state=42)\n\n# 5 fold stratify for cv\n\ncv = StratifiedKFold(5, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:39.269124Z","iopub.execute_input":"2022-02-21T10:09:39.269567Z","iopub.status.idle":"2022-02-21T10:09:39.372579Z","shell.execute_reply.started":"2022-02-21T10:09:39.269506Z","shell.execute_reply":"2022-02-21T10:09:39.371649Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# setting model hyperparameters, didn't include fine tuning here because of timing reasons...\n\nxg = xgb.XGBClassifier(\n    n_estimators=750,\n    min_child_weight=0.81,\n    learning_rate=0.025,\n    max_depth=2,\n    subsample=0.80,\n    colsample_bytree=0.42,\n    gamma=0.10,\n    random_state=42,\n    n_jobs=-1,\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:39.374027Z","iopub.execute_input":"2022-02-21T10:09:39.374389Z","iopub.status.idle":"2022-02-21T10:09:39.381029Z","shell.execute_reply.started":"2022-02-21T10:09:39.374345Z","shell.execute_reply":"2022-02-21T10:09:39.380144Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"estimators = [xg]","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:39.382225Z","iopub.execute_input":"2022-02-21T10:09:39.382511Z","iopub.status.idle":"2022-02-21T10:09:39.395099Z","shell.execute_reply.started":"2022-02-21T10:09:39.382480Z","shell.execute_reply":"2022-02-21T10:09:39.394359Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# cross validation scheme\n\ndef model_check(X_train, y_train, estimators, cv):\n    model_table = pd.DataFrame()\n\n    row_index = 0\n    for est in estimators:\n\n        MLA_name = est.__class__.__name__\n        model_table.loc[row_index, 'Model Name'] = MLA_name\n\n        cv_results = cross_validate(est,\n                                    X_train,\n                                    y_train,\n                                    cv=cv,\n                                    scoring='roc_auc',\n                                    return_train_score=True,\n                                    n_jobs=-1)\n\n        model_table.loc[row_index,\n                        'Train roc Mean'] = cv_results['train_score'].mean()\n        model_table.loc[row_index,\n                        'Test roc Mean'] = cv_results['test_score'].mean()\n        model_table.loc[row_index, 'Test Std'] = cv_results['test_score'].std()\n        model_table.loc[row_index, 'Time'] = cv_results['fit_time'].mean()\n\n        row_index += 1\n\n    model_table.sort_values(by=['Test roc Mean'],\n                            ascending=False,\n                            inplace=True)\n\n    return model_table","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:39.396185Z","iopub.execute_input":"2022-02-21T10:09:39.396629Z","iopub.status.idle":"2022-02-21T10:09:39.408803Z","shell.execute_reply.started":"2022-02-21T10:09:39.396595Z","shell.execute_reply":"2022-02-21T10:09:39.407897Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# Model Results Based on Meta Features","metadata":{}},{"cell_type":"code","source":"# display cv results\n\nraw_models = model_check(X_train, y_train, estimators, cv)\ndisplay(raw_models)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:09:39.410354Z","iopub.execute_input":"2022-02-21T10:09:39.410604Z","iopub.status.idle":"2022-02-21T10:14:39.685944Z","shell.execute_reply.started":"2022-02-21T10:09:39.410575Z","shell.execute_reply":"2022-02-21T10:14:39.684718Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# fitting train data\n\nxg.fit(X_train, y_train)\n\n# predicting on holdout set\nvalidation = xg.predict_proba(X_test)[:, 1]\n\n# checking results on validation set\nroc_auc_score(y_test, validation)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:14:39.688608Z","iopub.execute_input":"2022-02-21T10:14:39.689696Z","iopub.status.idle":"2022-02-21T10:15:07.332782Z","shell.execute_reply.started":"2022-02-21T10:14:39.689640Z","shell.execute_reply":"2022-02-21T10:15:07.331957Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"# Meta Feature Importances","metadata":{}},{"cell_type":"code","source":"# finding feature importances and creating new dataframe basen on them\n\nfeature_importance = xg.get_booster().get_score(importance_type='weight')\n\nkeys = list(feature_importance.keys())\nvalues = list(feature_importance.values())\n\nimportance = pd.DataFrame(data=values, index=keys,\n                          columns=['score']).sort_values(by='score',\n                                                         ascending=False)\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.barplot(x=importance.score.iloc[:20],\n            y=importance.index[:20],\n            orient='h',\n            palette='Reds_r')\nax.set_title('Feature Importances')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:15:07.334316Z","iopub.execute_input":"2022-02-21T10:15:07.334618Z","iopub.status.idle":"2022-02-21T10:15:07.804710Z","shell.execute_reply.started":"2022-02-21T10:15:07.334586Z","shell.execute_reply":"2022-02-21T10:15:07.803704Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# First Step: Creating Meta Submission","metadata":{}},{"cell_type":"code","source":"# predicting on test set\n\npredictions = xg.predict_proba(test)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:07.806395Z","iopub.execute_input":"2022-02-21T10:15:07.806644Z","iopub.status.idle":"2022-02-21T10:15:07.863626Z","shell.execute_reply.started":"2022-02-21T10:15:07.806616Z","shell.execute_reply":"2022-02-21T10:15:07.862891Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# creating submission df\n\n\nmeta_df = pd.DataFrame(columns=['image_name', 'target'])\n\n# assigning predictions on submission df\n\nmeta_df['image_name'] = sample['image_name']\nmeta_df['target'] = predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:07.865087Z","iopub.execute_input":"2022-02-21T10:15:07.865588Z","iopub.status.idle":"2022-02-21T10:15:07.879094Z","shell.execute_reply.started":"2022-02-21T10:15:07.865544Z","shell.execute_reply":"2022-02-21T10:15:07.878366Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# creating submission csv file\n\nmeta_df.to_csv('meta_with_img_data.csv', header=True, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:07.880840Z","iopub.execute_input":"2022-02-21T10:15:07.881496Z","iopub.status.idle":"2022-02-21T10:15:07.930944Z","shell.execute_reply.started":"2022-02-21T10:15:07.881452Z","shell.execute_reply":"2022-02-21T10:15:07.930239Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### The .csv file above scores ~85% on public LB but our inspections on train/test data shows it might be overfitting due to image differences, in next step we going try spot these features and make it little more robust...","metadata":{}},{"cell_type":"markdown","source":"# Adversarial Validation\n\nAlright, since we have high doubts for train test sampling wanted to implement what is called 'Adversarial Validation'. For this we going to replace our targets for both datasets (0 for train and 1 for test), then we going build a classifier which tries to predict which observation belongs to train and which one belongs to test set. If datasets randomly selected from similar roots it should be really hard for the classifier to separate them. But if there is systematic selection differences between train and test sets then classifier should be able to capture this trend. So we want our models score lower for the next section because higher detection rate means higher difference between train and test datasets, so let's get started...\n","metadata":{}},{"cell_type":"code","source":"adv_train = train.copy()\nadv_train.drop('target', axis=1, inplace=True)\nadv_test = test.copy()\n\nadv_train['dataset_label'] = 0\nadv_test['dataset_label'] = 1\n\nadv_master = pd.concat([adv_train, adv_test], axis=0)\n\nadv_X = adv_master.drop('dataset_label', axis=1)\nadv_y = adv_master['dataset_label']","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:07.932735Z","iopub.execute_input":"2022-02-21T10:15:07.933390Z","iopub.status.idle":"2022-02-21T10:15:08.225626Z","shell.execute_reply.started":"2022-02-21T10:15:07.933346Z","shell.execute_reply":"2022-02-21T10:15:08.224640Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"adv_X_train, adv_X_test, adv_y_train, adv_y_test = train_test_split(adv_X,\n                                                    adv_y,\n                                                    test_size=0.4,\n                                                    stratify=adv_y,\n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:08.227050Z","iopub.execute_input":"2022-02-21T10:15:08.227331Z","iopub.status.idle":"2022-02-21T10:15:08.352125Z","shell.execute_reply.started":"2022-02-21T10:15:08.227300Z","shell.execute_reply":"2022-02-21T10:15:08.351149Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"xg_adv = xgb.XGBClassifier(\n    random_state=42,\n    n_jobs=-1,\n)\n\n# Fitting train data\n\nxg_adv.fit(adv_X_train, adv_y_train)\n\n# Predicting on holdout set\nvalidation = xg_adv.predict_proba(adv_X_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:08.353826Z","iopub.execute_input":"2022-02-21T10:15:08.354155Z","iopub.status.idle":"2022-02-21T10:15:28.000240Z","shell.execute_reply.started":"2022-02-21T10:15:08.354120Z","shell.execute_reply":"2022-02-21T10:15:27.999538Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def plot_roc_feat(y_trues, y_preds, labels, est, x_max=1.0):\n    fig, ax = plt.subplots(1,2, figsize=(16,6))\n    for i, y_pred in enumerate(y_preds):\n        y_true = y_trues[i]\n        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n        auc = roc_auc_score(y_true, y_pred)\n        ax[0].plot(fpr, tpr, label='%s; AUC=%.3f' % (labels[i], auc), marker='o', markersize=1)\n\n    ax[0].legend()\n    ax[0].grid()\n    ax[0].plot(np.linspace(0, 1, 20), np.linspace(0, 1, 20), linestyle='--')\n    ax[0].set_title('ROC curve')\n    ax[0].set_xlabel('False Positive Rate')\n    ax[0].set_xlim([-0.01, x_max])\n    _ = ax[0].set_ylabel('True Positive Rate')\n    \n    \n    feature_importance = est.get_booster().get_score(importance_type='weight')\n\n    keys = list(feature_importance.keys())\n    values = list(feature_importance.values())\n\n    importance = pd.DataFrame(data=values, index=keys,\n                          columns=['score']).sort_values(by='score',\n                                                         ascending=False)\n    \n    sns.barplot(x=importance.score.iloc[:20],\n            y=importance.index[:20],\n            orient='h',\n            palette='Reds_r', ax=ax[1])\n    ax[1].set_title('Feature Importances')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:15:28.001795Z","iopub.execute_input":"2022-02-21T10:15:28.002300Z","iopub.status.idle":"2022-02-21T10:15:28.017520Z","shell.execute_reply.started":"2022-02-21T10:15:28.002240Z","shell.execute_reply":"2022-02-21T10:15:28.016691Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"## First Results","metadata":{}},{"cell_type":"code","source":"plot_roc_feat(\n    [adv_y_test],\n    [validation],\n    ['Baseline'],\n    xg_adv\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:28.018697Z","iopub.execute_input":"2022-02-21T10:15:28.019797Z","iopub.status.idle":"2022-02-21T10:15:28.788814Z","shell.execute_reply.started":"2022-02-21T10:15:28.019751Z","shell.execute_reply":"2022-02-21T10:15:28.787839Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"## Let's drop image size and number related features to see if it's increase the randomness...","metadata":{}},{"cell_type":"code","source":"adv_X.drop(['n_images', 'image_size','width','height','total_pixels','reds','blues','greens','mean_colors',\n            'age_min', 'age_max'], axis=1, inplace=True)\n\n\nadv_X_train, adv_X_test, adv_y_train, adv_y_test = train_test_split(adv_X,\n                                                    adv_y,\n                                                    test_size=0.4,\n                                                    stratify=adv_y,\n                                                    random_state=42)\n\n# fitting train data\n\nxg_adv.fit(adv_X_train, adv_y_train)\n\n# predicting on holdout set\nvalidation = xg_adv.predict_proba(adv_X_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:28.790256Z","iopub.execute_input":"2022-02-21T10:15:28.790650Z","iopub.status.idle":"2022-02-21T10:15:46.534563Z","shell.execute_reply.started":"2022-02-21T10:15:28.790604Z","shell.execute_reply":"2022-02-21T10:15:46.533809Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"## Well yeah, it did! The more close our AUC 50% the better, so for now we can continue what we have for now.","metadata":{}},{"cell_type":"code","source":"plot_roc_feat(\n    [adv_y_test],\n    [validation],\n    ['Baseline'],\n    xg_adv\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:46.535721Z","iopub.execute_input":"2022-02-21T10:15:46.536537Z","iopub.status.idle":"2022-02-21T10:15:47.288949Z","shell.execute_reply.started":"2022-02-21T10:15:46.536485Z","shell.execute_reply":"2022-02-21T10:15:47.287793Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"X_train.drop(['n_images', 'image_size','width','height','total_pixels','reds','blues','greens','mean_colors', 'age_min', 'age_max'], axis=1, inplace=True)\n#X_test.drop(['n_images', 'image_size','width','height','total_pixels','reds','blues','greens','mean_colors', 'age_min', 'age_max'], axis=1, inplace=True)\n\ntest.drop(['n_images', 'image_size','width','height','total_pixels','reds','blues','greens','mean_colors', 'age_min', 'age_max'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:47.290297Z","iopub.execute_input":"2022-02-21T10:15:47.290557Z","iopub.status.idle":"2022-02-21T10:15:47.322832Z","shell.execute_reply.started":"2022-02-21T10:15:47.290524Z","shell.execute_reply":"2022-02-21T10:15:47.321865Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"# Simplified Meta Predictions","metadata":{}},{"cell_type":"code","source":"xg= xgb.XGBClassifier(\n    n_estimators=750,\n    learning_rate=0.015,\n    min_child_weight= 218,\n    max_delta_step= 4,\n    max_depth= 2,\n    subsample= 0.751,\n    colsample_bytree= 0.77,\n    gamma= 24,\n    reg_lambda= 11,\n    random_state=42,\n    n_jobs=-1,\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-21T10:15:47.324006Z","iopub.execute_input":"2022-02-21T10:15:47.324217Z","iopub.status.idle":"2022-02-21T10:15:47.329732Z","shell.execute_reply.started":"2022-02-21T10:15:47.324192Z","shell.execute_reply":"2022-02-21T10:15:47.328927Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# display cv results\n\nraw_models = model_check(X_train, y_train, [xg], cv)\ndisplay(raw_models)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:15:47.331180Z","iopub.execute_input":"2022-02-21T10:15:47.331444Z","iopub.status.idle":"2022-02-21T10:19:12.379725Z","shell.execute_reply.started":"2022-02-21T10:15:47.331416Z","shell.execute_reply":"2022-02-21T10:19:12.378959Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# fitting train data\n\nxg.fit(X_train, y_train)\n\npredictions = xg.predict_proba(test)[:, 1]\n\nmeta_df = pd.DataFrame(columns=['image_name', 'target'])\n\n# assigning predictions on submission df\n\nmeta_df['image_name'] = sample['image_name']\nmeta_df['target'] = predictions\n\n# creating submission csv file\n\nmeta_df.to_csv('meta_simplified_img_data.csv', header=True, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:12.380851Z","iopub.execute_input":"2022-02-21T10:19:12.381196Z","iopub.status.idle":"2022-02-21T10:19:38.946677Z","shell.execute_reply.started":"2022-02-21T10:19:12.381157Z","shell.execute_reply":"2022-02-21T10:19:38.945959Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# End of Tabular Data Part\n\nThis simple approach including basic info as tabular data with good old ML algoithms gave me LB score of 0.8484! ","metadata":{}},{"cell_type":"markdown","source":"# Machine Learning to Neural Networks","metadata":{}},{"cell_type":"code","source":"# Importing packages\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport efficientnet.tfkeras as efn\nfrom kaggle_datasets import KaggleDatasets\n\ntf.random.set_seed(seed_val)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:38.947772Z","iopub.execute_input":"2022-02-21T10:19:38.948580Z","iopub.status.idle":"2022-02-21T10:19:39.280375Z","shell.execute_reply.started":"2022-02-21T10:19:38.948525Z","shell.execute_reply":"2022-02-21T10:19:39.279431Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# Loading image storage buckets\n\nGCS_PATH = KaggleDatasets().get_gcs_path('melanoma-384x384')\n\nfilenames_train = np.array(tf.io.gfile.glob(GCS_PATH + '/train*.tfrec'))\nfilenames_test = np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec'))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:39.281688Z","iopub.execute_input":"2022-02-21T10:19:39.282005Z","iopub.status.idle":"2022-02-21T10:19:39.866572Z","shell.execute_reply.started":"2022-02-21T10:19:39.281965Z","shell.execute_reply":"2022-02-21T10:19:39.865592Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Setting TPU as main device for training, if you get warnings while working with tpu's ignore them.\n\nDEVICE = 'TPU'\nif DEVICE == 'TPU':\n    print('connecting to TPU...')\n    try:        \n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print('Could not connect to TPU')\n        tpu = None\n\n    if tpu:\n        try:\n            print('Initializing  TPU...')\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print('TPU initialized')\n        except _:\n            print('Failed to initialize TPU!')\n    else:\n        DEVICE = 'GPU'\n\nif DEVICE != 'TPU':\n    print('Using default strategy for CPU and single GPU')\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == 'GPU':\n    print('Num GPUs Available: ',\n          len(tf.config.experimental.list_physical_devices('GPU')))\n\nprint('REPLICAS: ', strategy.num_replicas_in_sync)\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:39.868009Z","iopub.execute_input":"2022-02-21T10:19:39.868253Z","iopub.status.idle":"2022-02-21T10:19:46.118481Z","shell.execute_reply.started":"2022-02-21T10:19:39.868225Z","shell.execute_reply":"2022-02-21T10:19:46.117780Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"Here we set config for our next steps. You can play with these but mind the memory sizes with the batches & image sizes.","metadata":{}},{"cell_type":"code","source":"# you can edit these settings.\n\ncfg = dict(\n           batch_size=32,\n           img_size=384,\n    \n           lr_start=0.000005,\n           lr_max=0.00000125,\n           lr_min=0.000001,\n           lr_rampup=5,\n           lr_sustain=0,\n           lr_decay=0.8,\n           epochs=12,\n    \n           transform_prob=1.0,\n           rot=180.0,\n           shr=2.0,\n           hzoom=8.0,\n           wzoom=8.0,\n           hshift=8.0,\n           wshift=8.0,\n    \n           optimizer='adam',\n           label_smooth_fac=0.05,\n           tta_steps=20\n            \n        )","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:46.121846Z","iopub.execute_input":"2022-02-21T10:19:46.122205Z","iopub.status.idle":"2022-02-21T10:19:46.129386Z","shell.execute_reply.started":"2022-02-21T10:19:46.122173Z","shell.execute_reply":"2022-02-21T10:19:46.128339Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def get_mat(rotation, shear, height_zoom, width_zoom, height_shift,\n            width_shift):\n    \n    ''' Settings for image preparations '''\n\n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    shear = math.pi * shear / 180.\n\n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1], dtype='float32')\n    zero = tf.constant([0], dtype='float32')\n    rotation_matrix = tf.reshape(\n        tf.concat([c1, s1, zero, -s1, c1, zero, zero, zero, one], axis=0),\n        [3, 3])\n\n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape(\n        tf.concat([one, s2, zero, zero, c2, zero, zero, zero, one], axis=0),\n        [3, 3])\n\n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape(\n        tf.concat([\n            one / height_zoom, zero, zero, zero, one / width_zoom, zero, zero,\n            zero, one\n        ],\n                  axis=0), [3, 3])\n\n    # SHIFT MATRIX\n    shift_matrix = tf.reshape(\n        tf.concat(\n            [one, zero, height_shift, zero, one, width_shift, zero, zero, one],\n            axis=0), [3, 3])\n\n    return K.dot(K.dot(rotation_matrix, shear_matrix),\n                 K.dot(zoom_matrix, shift_matrix))\n\n\ndef transform(image, cfg):\n    \n    ''' This function takes input images of [: , :, 3] sizes and returns them as randomly rotated, sheared, shifted and zoomed. '''\n\n    DIM = cfg['img_size']\n    XDIM = DIM % 2  # fix for size 331\n\n    rot = cfg['rot'] * tf.random.normal([1], dtype='float32')\n    shr = cfg['shr'] * tf.random.normal([1], dtype='float32')\n    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['hzoom']\n    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['wzoom']\n    h_shift = cfg['hshift'] * tf.random.normal([1], dtype='float32')\n    w_shift = cfg['wshift'] * tf.random.normal([1], dtype='float32')\n\n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot, shr, h_zoom, w_zoom, h_shift, w_shift)\n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat(tf.range(DIM // 2, -DIM // 2, -1), DIM)\n    y = tf.tile(tf.range(-DIM // 2, DIM // 2), [DIM])\n    z = tf.ones([DIM * DIM], dtype='int32')\n    idx = tf.stack([x, y, z])\n\n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n    idx2 = K.cast(idx2, dtype='int32')\n    idx2 = K.clip(idx2, -DIM // 2 + XDIM + 1, DIM // 2)\n\n    # FIND ORIGIN PIXEL VALUES\n    idx3 = tf.stack([DIM // 2 - idx2[0, ], DIM // 2 - 1 + idx2[1, ]])\n    d = tf.gather_nd(image, tf.transpose(idx3))\n\n    return tf.reshape(d, [DIM, DIM, 3])\n\ndef prepare_image(img, cfg=None, augment=True):\n    \n    ''' This function loads the image, resizes it, casts a tensor to a new type float32 in our case, transforms it using the function just above, then applies the augmentations.'''\n    \n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [cfg['img_size'], cfg['img_size']],\n                          antialias=True)\n    img = tf.cast(img, tf.float32) / 255.0\n\n    if augment:\n        if cfg['transform_prob'] > tf.random.uniform([1], minval=0, maxval=1):\n            img = transform(img, cfg)\n\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_saturation(img, 0.7, 1.3)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        img = tf.image.random_brightness(img, 0.1)\n\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:46.130784Z","iopub.execute_input":"2022-02-21T10:19:46.131147Z","iopub.status.idle":"2022-02-21T10:19:46.158689Z","shell.execute_reply.started":"2022-02-21T10:19:46.131110Z","shell.execute_reply":"2022-02-21T10:19:46.157754Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"def read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'image_name': tf.io.FixedLenFeature([], tf.string),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n        'sex': tf.io.FixedLenFeature([], tf.int64),\n        'age_approx': tf.io.FixedLenFeature([], tf.int64),\n        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n        'diagnosis': tf.io.FixedLenFeature([], tf.int64),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        #'width': tf.io.FixedLenFeature([], tf.int64),\n        #'height': tf.io.FixedLenFeature([], tf.int64)\n    }\n\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    return example['image'], example['target']\n\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'image_name': tf.io.FixedLenFeature([], tf.string),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n        'sex': tf.io.FixedLenFeature([], tf.int64),\n        'age_approx': tf.io.FixedLenFeature([], tf.int64),\n        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    return example['image'], example['image_name']\n\ndef count_data_items(filenames):\n    n = [\n        int(re.compile(r'-([0-9]*)\\.').search(filename).group(1))\n        for filename in filenames\n    ]\n    return np.sum(n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:46.160220Z","iopub.execute_input":"2022-02-21T10:19:46.160726Z","iopub.status.idle":"2022-02-21T10:19:46.176395Z","shell.execute_reply.started":"2022-02-21T10:19:46.160688Z","shell.execute_reply":"2022-02-21T10:19:46.175670Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"def getTrainDataset(files, cfg, augment=True, shuffle=True):\n    \n    ''' This function reads the tfrecord train images, shuffles them, apply augmentations to them and prepares the data for training. '''\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n\n    if shuffle:\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n\n    ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n    ds = ds.repeat()\n    if shuffle:\n        ds = ds.shuffle(2048)\n    ds = ds.map(lambda img, label:\n                (prepare_image(img, augment=augment, cfg=cfg), label),\n                num_parallel_calls=AUTO)\n    ds = ds.batch(cfg['batch_size'] * strategy.num_replicas_in_sync)\n    ds = ds.prefetch(AUTO)\n    return ds\n\ndef getTestDataset(files, cfg, augment=False, repeat=False):\n    \n    ''' This function reads the tfrecord test images and prepares the data for predicting. '''\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    if repeat:\n        ds = ds.repeat()\n    ds = ds.map(read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    ds = ds.map(lambda img, idnum:\n                (prepare_image(img, augment=augment, cfg=cfg), idnum),\n                num_parallel_calls=AUTO)\n    ds = ds.batch(cfg['batch_size'] * strategy.num_replicas_in_sync)\n    ds = ds.prefetch(AUTO)\n    return ds\n\ndef get_model():\n    \n    ''' This function gets the layers inclunding efficientnet ones. '''\n    \n    model_input = tf.keras.Input(shape=(cfg['img_size'], cfg['img_size'], 3),\n                                 name='img_input')\n\n    dummy = tf.keras.layers.Lambda(lambda x: x)(model_input)\n\n    outputs = []\n\n    x = efn.EfficientNetB3(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(cfg['img_size'], cfg['img_size'], 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    outputs.append(x)\n\n    x = efn.EfficientNetB4(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(cfg['img_size'], cfg['img_size'], 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    outputs.append(x)\n\n    x = efn.EfficientNetB5(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(cfg['img_size'], cfg['img_size'], 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    outputs.append(x)\n\n    model = tf.keras.Model(model_input, outputs, name='aNetwork')\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:46.178720Z","iopub.execute_input":"2022-02-21T10:19:46.178980Z","iopub.status.idle":"2022-02-21T10:19:46.198117Z","shell.execute_reply.started":"2022-02-21T10:19:46.178948Z","shell.execute_reply":"2022-02-21T10:19:46.197332Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"def compileNewModel(cfg):\n    \n    ''' Configuring the model with losses and metrics. '''    \n    \n    with strategy.scope():\n        model = get_model()\n\n    with strategy.scope():\n        model.compile(optimizer=cfg['optimizer'],\n                      loss=[\n                          tf.keras.losses.BinaryCrossentropy(\n                              label_smoothing=cfg['label_smooth_fac']),\n                          tf.keras.losses.BinaryCrossentropy(\n                              label_smoothing=cfg['label_smooth_fac']),\n                          tf.keras.losses.BinaryCrossentropy(\n                              label_smoothing=cfg['label_smooth_fac'])\n                      ],\n                      metrics=[tf.keras.metrics.AUC(name='auc')])\n    return model\n\ndef getLearnRateCallback(cfg):\n    \n    ''' Using callbacks for learning rate adjustments. '''\n    \n    lr_start = cfg['lr_start']\n    lr_max = cfg['lr_max'] * strategy.num_replicas_in_sync * cfg['batch_size']\n    lr_min = cfg['lr_min']\n    lr_rampup = cfg['lr_rampup']\n    lr_sustain = cfg['lr_sustain']\n    lr_decay = cfg['lr_decay']\n\n    def lrfn(epoch):\n        if epoch < lr_rampup:\n            lr = (lr_max - lr_start) / lr_rampup * epoch + lr_start\n        elif epoch < lr_rampup + lr_sustain:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_rampup -\n                                                lr_sustain) + lr_min\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\ndef learnModel(model, ds_train, stepsTrain, cfg, ds_val=None, stepsVal=0):\n    \n    ''' Fitting things together for training '''\n    \n    callbacks = [getLearnRateCallback(cfg)]\n\n    history = model.fit(ds_train,\n                        validation_data=ds_val,\n                        verbose=1,\n                        steps_per_epoch=stepsTrain,\n                        validation_steps=stepsVal,\n                        epochs=cfg['epochs'],\n                        callbacks=callbacks)\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:46.199531Z","iopub.execute_input":"2022-02-21T10:19:46.200174Z","iopub.status.idle":"2022-02-21T10:19:46.216327Z","shell.execute_reply.started":"2022-02-21T10:19:46.200135Z","shell.execute_reply":"2022-02-21T10:19:46.215660Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# getting train data\n\nds_train = getTrainDataset(\n    filenames_train, cfg).map(lambda img, label: (img, (label, label, label)))\nstepsTrain = count_data_items(filenames_train) / \\\n    (cfg['batch_size'] * strategy.num_replicas_in_sync)\n\n# compiling and training model\n\nmodel = compileNewModel(cfg)\nlearnModel(model, ds_train, stepsTrain, cfg)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:19:46.217693Z","iopub.execute_input":"2022-02-21T10:19:46.218390Z","iopub.status.idle":"2022-02-21T11:02:09.630298Z","shell.execute_reply.started":"2022-02-21T10:19:46.218357Z","shell.execute_reply":"2022-02-21T11:02:09.629437Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"steps = count_data_items(filenames_test) / \\\n    (cfg['batch_size'] * strategy.num_replicas_in_sync)\n\nz = np.zeros((cfg['batch_size'] * strategy.num_replicas_in_sync))\n\n# loading test data\n\nds_testAug = getTestDataset(\n    filenames_test, cfg, augment=True,\n    repeat=True).map(lambda img, label: (img, (z, z, z)))\n\n# test time augmentations for predictions (20 in our case, you can increase it a little in cfg) and taking mean of them\n\nprobs = model.predict(ds_testAug, verbose=1, steps=steps * cfg['tta_steps'])\nprobs = np.stack(probs)\nprobs = probs[:, :count_data_items(filenames_test) * cfg['tta_steps']]\nprobs = np.stack(np.split(probs, cfg['tta_steps'], axis=1), axis=1)\nprobs = np.mean(probs, axis=1)\n\ntest = pd.read_csv(os.path.join(base_path, 'test.csv'))\n\ny_test_sorted = np.zeros((3, probs.shape[1]))\ntest = test.reset_index()\ntest = test.set_index('image_name')\n\ni = 0\nds_test = getTestDataset(filenames_test, cfg)\nfor img, imgid in tqdm(iter(ds_test.unbatch())):\n    imgid = imgid.numpy().decode('utf-8')\n    y_test_sorted[:, test.loc[imgid]['index']] = probs[:, i, 0]\n    i += 1\n\n    \n# creating .csv files for each effnet\n    \nfor i in range(y_test_sorted.shape[0]):\n    submission = sample\n    submission['target'] = y_test_sorted[i]\n    submission.to_csv('submission_model_%s.csv' % i, index=False)\n\n# blending effnets into a single .csv file    \n\nsubmission = sample\nsubmission['target'] = np.mean(y_test_sorted, axis=0)\nsubmission.to_csv('blended_effnets.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T11:02:09.632333Z","iopub.execute_input":"2022-02-21T11:02:09.633039Z","iopub.status.idle":"2022-02-21T11:09:41.583717Z","shell.execute_reply.started":"2022-02-21T11:02:09.632994Z","shell.execute_reply":"2022-02-21T11:09:41.582842Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"# Ensembling With Meta","metadata":{}},{"cell_type":"code","source":"# loading recently created .csv files from working directory\n\neffnet = pd.read_csv('./blended_effnets.csv')\nmeta = pd.read_csv('./meta_simplified_img_data.csv')\n\n\nsample['target'] = (\n                           \n                           effnet['target'] * 0.9 +\n                           meta['target'] * 0.1 \n                          \n                          )\n\n# final submissions\n\nsample.to_csv('ensembled.csv', header=True, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T11:09:41.585249Z","iopub.execute_input":"2022-02-21T11:09:41.585506Z","iopub.status.idle":"2022-02-21T11:09:41.661324Z","shell.execute_reply.started":"2022-02-21T11:09:41.585478Z","shell.execute_reply":"2022-02-21T11:09:41.660333Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"# Submission and Some Notes","metadata":{}},{"cell_type":"code","source":"sample.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T11:09:41.662664Z","iopub.execute_input":"2022-02-21T11:09:41.662883Z","iopub.status.idle":"2022-02-21T11:09:41.673515Z","shell.execute_reply.started":"2022-02-21T11:09:41.662857Z","shell.execute_reply":"2022-02-21T11:09:41.672491Z"},"trusted":true},"execution_count":83,"outputs":[]}]}